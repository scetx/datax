{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Introduction to Time Series\n",
    "\n",
    "##### Summary\n",
    "- Measuring error with MAPE\n",
    "- Selecting parameters in exponential smoothing\n",
    "- Comparing ARIMA and SARIMA\n",
    "- Holiday effects with Facebook's Prophet library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Measuring Error with MAPE\n",
    "\n",
    "The Mean Absolute Percentage Error (MAPE) is a common metric for measuring error in forecasts. The MAPE represents error as a percentage of the actual observed values. A high MAPE value means the error is large relative to the quantity being measuring and so the forecast is poor. A small MAPE means the error is relatively small so the forecast is good.\n",
    "\n",
    "The MAPE is given by:\n",
    "\n",
    "$$ MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{|F_t - A_t|}{A_t} $$\n",
    "\n",
    "where $A_t$ is the actual observed value, $F_t$ is the forecast, and $n$ is the number of data points the MAPE is being calculated over. Read about MAPE at https://en.wikipedia.org/wiki/Mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Write a function `get_mape` that calculates the MAPE for a set of forecasts and actuals. The inputs to the function are two <i> pd.series called </i> `actuals` and `forecasts`. The function returns the MAPE as decimal rounded to 4 decimal places (i.e. MAPE = 0.1032)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(actuals, forecasts):\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selecting Parameters in Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Plot the avocado weekly sales dataset to understand the trend and seasonality. Does the trend appear to be multiplicative or additive? Does the seasonality appear to be multiplicative or additive?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and process the weekly avocado sales dataset\n",
    "avocado = pd.read_csv('avocado_sales.csv')\n",
    "\n",
    "def convert_to_datetime(df, freq):\n",
    "    df[\"Date\"]= pd.to_datetime(df[\"Date\"])\n",
    "    df.sort_values(by ='Date', ascending = True, inplace = True)\n",
    "    df.set_index(\"Date\", inplace = True)\n",
    "    output_df = df.asfreq(freq)\n",
    "    return output_df\n",
    "\n",
    "avocado = convert_to_datetime(avocado, 'W-Sun')\n",
    "\n",
    "### YOUR CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Use Triple Exponential Smoothing to create weekly avocado sales forecasts for June 2018 and onward (95 weeks into the future). Fit a model with parameter values recommended by the model and train on data collected from May 2018 and prior.**\n",
    "\n",
    "- `trend` = [FROM PART A]\n",
    "- `seasonal` = [FROM PART A]\n",
    "- `seasonal_periods` = ?\n",
    "- `smoothing_level` = Recommended by model\n",
    "- `smoothing_slope` = Recommended by model\n",
    "- `smoothing_seasonal` = Recommended by model\n",
    "\n",
    "Hint: Remember we can let the model recommend parameters by passing no inputs into the `fit` method:  `ExponentialSmoothing(...).fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "train = avocado[avocado.index <= '2018-05-31']\n",
    "test = avocado[avocado.index >= '2018-06-01']\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "model = ...\n",
    "\n",
    "# Fit model\n",
    "fit = ...\n",
    "\n",
    "# Forecast 95 months out\n",
    "pred = ...\n",
    "\n",
    "# Plot the training set, forecast, and test set\n",
    "#plt.plot(pred, label = 'forecast')\n",
    "#plt.plot(train['Units Sold'], label = 'train')\n",
    "#plt.plot(test['Units Sold'], label = 'test')\n",
    "#plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Now use Triple Exponential Smoothing to create weekly avocado sales forecasts for June 2018 and onward (95 weeks into the future) but use the following model parameters. Again fit a model on the training data collected from May 2018 and prior. Is the forecast better when the model recommends parameters or with these values?** \n",
    "- `trend` = [FROM PART A]\n",
    "- `seasonal` = [FROM PART A]\n",
    "- `seasonal_periods` = ?\n",
    "- `smoothing_level` = 0.2\n",
    "- `smoothing_slope` = 0.2 \n",
    "- `smoothing_seasonal` = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "train = avocado[avocado.index <= '2018-05-31']\n",
    "test = avocado[avocado.index >= '2018-06-01']\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "model = ...\n",
    "\n",
    "# Fit models\n",
    "fit = ...\n",
    "\n",
    "# Forecast 95 months out\n",
    "pred = ...\n",
    "\n",
    "# Plot the training set, forecast, and test set\n",
    "#plt.plot(pred, label = 'forecast')\n",
    "#plt.plot(train['Units Sold'], label = 'train')\n",
    "#plt.plot(test['Units Sold'], label = 'test')\n",
    "#plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Calculate the MAPE as the `smoothing_slope` parameter changes from 0.01 to 1 in intervals of 0.01. Train your model on all data from May 2018 and prior. Calculate the MAPE by comparing the 95 weeks of forecasts to the test set (June 2018 and onward). Record the MAPE values in a list called `mapes` where the first element is calculated with beta = 0.01 and the last value is calculated with beta = 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = avocado[avocado.index <= '2018-05-31']\n",
    "test = avocado[avocado.index >= '2018-06-01']\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "def score_train_model(model, beta):\n",
    "    # Fit model\n",
    "    fit = ...\n",
    "\n",
    "    # Forecast 95 months out\n",
    "    pred = ...\n",
    "    return get_mape(test['Units Sold'], pred)\n",
    "\n",
    "\n",
    "model = ...\n",
    "mapes = []\n",
    "betas = np.arange(0.1, 1.0, 0.01)\n",
    "\n",
    "for b in betas:\n",
    "    score = ...\n",
    "    mapes.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the error below. We should see that the error is minimized when beta is between about 0.2 and 0.4. A similar searching method can be used to select the other parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MAPE against Betas\n",
    "#plt.plot(betas, mapes)\n",
    "#plt.xlabel('Betas')\n",
    "#plt.ylabel('MAPE')\n",
    "#plt.title('Mean Absolute Percentage Error (MAPE) vs. Betas');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparing ARIMA and SARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Use an ARIMA model to forecast weekly avocado sales for June 2018 and onward (95 weeks into the future). Train the model on the data from May 2018 and prior. Use the following  parameters. Then plot the ARIMA forecast, test set, and training set.**\n",
    "- Differencing order = 1\n",
    "- Autoregressive order = 1\n",
    "- Moving average order = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Define model\n",
    "model = ...\n",
    "\n",
    "# Fit model\n",
    "model_fit = ...\n",
    "\n",
    "# Create forecasts\n",
    "#output = model_fit.forecast(95)\n",
    "#arima_pred = output[0]\n",
    "\n",
    "# Plot forecast, test set, and training set\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Use a SARIMA model to forecast weekly avocado sales for June 2018 and onward (95 weeks into the future). Train the model on the data from May 2018 and before. Use the following  parameters. Then plot the SARIMA forecast, test set, and training set.**\n",
    "- Differencing order = 1\n",
    "- Autoregressive order = 1\n",
    "- Moving average order = 1\n",
    "- Seasonal differencing order = 1\n",
    "- Seasonal autoregressive order = 1\n",
    "- Seasonal moving average order = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "# Define model\n",
    "model = ...\n",
    "\n",
    "# Fit model\n",
    "model_fit = ...\n",
    "\n",
    "# Create forecasts\n",
    "sarima_pred = ...\n",
    "\n",
    "# Plot forecast, test set, and training set\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Calculate the MAPE of the ARIMA and SARIMA forecasts by comparing the 95 weeks of forecasts to the test set. How much did the MAPE improve when seasonality was accounted for?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA MAPE:  Ellipsis\n",
      "SARIMA MAPE:  Ellipsis\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "arima_mape = ...\n",
    "sarima_mape = ...\n",
    "\n",
    "print('ARIMA MAPE: ', arima_mape)\n",
    "print('SARIMA MAPE: ', sarima_mape)\n",
    "#print('Improvement: ', arima_mape - sarima_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Holiday Effects with Facebook's Prophet library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Use Prophet to forecast weekly avocado sales for June 2018 and onward (95 weeks into the future). Train the model on the data from May 2018 and before. Use Prophet's default parameters. Report the forecasts as `prophet_forecast`, a series with 95 forecasts where the first row is the forecast for the first week in June 2018.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "\n",
    "# Prophet requires the time series to be a 2 column data series with the Date as 'ds' and the values as 'y'.\n",
    "avocado_prophet = avocado.reset_index().rename(columns = {'Date':'ds', 'Units Sold':'y'})\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "...\n",
    "\n",
    "# Fit the model on the time series.\n",
    "...\n",
    "\n",
    "# Create a DataFrame of future dates to create forecasts for. \n",
    "...\n",
    "\n",
    "# Create forecasts\n",
    "prophet_forecast = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Use Prophet to forecast avocado sales again for June 2018 and onward (95 weeks into the future) but now add the Supebowl and Fourth of July holidays to the model. Train the model on the data from May 2018 and before. Use Prophet's default parameters for all other model features. Report the new forecasts as `prophet_forecast_holidays`, a series with 95 forecasts where the first row is the forecast for the first week in June 2018.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "prophet_forecast_holidays = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Calculate the MAPE of the Prophet model before account for holidays and after adding holidays. The MAPE should be calculated by comparing the 95 weeks of forecasts to the test set. How much did the MAPE improve when holidays were accounted for?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prophet MAPE:  Ellipsis\n",
      "Prophet with Holiday MAPE:  Ellipsis\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "prophet_mape = ...\n",
    "prophet_holiday_mape = ...\n",
    "\n",
    "print('Original Prophet MAPE: ', prophet_mape)\n",
    "print('Prophet with Holiday MAPE: ', prophet_holiday_mape)\n",
    "#print('Improvement: ', prophet_mape - prophet_holiday_mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
